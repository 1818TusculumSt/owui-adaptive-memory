# Adaptive Memory v4.0 ğŸ§ 

> **Intelligent, persistent memory for your LLMs**  
> Transform conversations into lasting knowledge with enterprise-grade memory management for Open WebUI.

## What is Adaptive Memory?

Adaptive Memory is a sophisticated plugin that gives Large Language Models persistent, personalized memory across conversations. It automatically extracts, categorizes, and retrieves user-specific informationâ€”creating natural, context-aware interactions that remember what matters.

## âœ¨ Key Features

### ğŸ¯ **Intelligent Memory Extraction**
Automatically identifies and stores facts, preferences, relationships, and goals from conversations using LLM-powered analysis with confidence scoring.

### ğŸ—ï¸ **Modular Architecture**
Built on a clean, pipeline-based design for reliability and extensibility:
- **EmbeddingManager**: Flexible embedding generation with local and API provider support
- **MemoryPipeline**: Core memory identification, retrieval, and processing logic
- **TaskManager**: Robust background task lifecycle with ghost task detection
- **ErrorManager**: Centralized error tracking and reporting
- **JSONParser**: Multi-strategy parsing with fallback mechanisms

### âš¡ **Advanced Background Processing**
- **Automatic Summarization**: Intelligently clusters and consolidates older memories (configurable interval, default 2 hours)
- **Semantic Deduplication**: Prevents duplicate memories using embedding-based similarity
- **Task Health Monitoring**: Built-in scavenger system detects and eliminates rogue tasks

### ğŸ¨ **Smart Categorization**
Organizes memories with:
- **Tags**: identity, preference, behavior, relationship, goal, possession
- **Memory Banks**: Personal, Work, General contexts for focused retrieval

### ğŸ” **Vector-Based Retrieval**
Efficient semantic search using cosine similarity with configurable thresholds and LRU caching for performance.

### ğŸ“Š **Enterprise Monitoring**
- **Prometheus Metrics**: Full instrumentation for embedding requests, retrieval latency, and error tracking
- **Real-time Status**: Live notifications during memory operations
- **Comprehensive Logging**: Timestamped, versioned logging throughout the pipeline

### ğŸ”Œ **Flexible Integration**
- **Embedding Providers**: Local SentenceTransformer models or OpenAI-compatible APIs
- **LLM Support**: Ollama and OpenAI-compatible endpoints with customizable configurations
- **Persistent Caching**: File-based embedding cache with automatic model compatibility validation

## ğŸ›ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Adaptive Memory v4.0                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ EmbeddingManagerâ”‚  â”‚  MemoryPipeline  â”‚                â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚
â”‚  â”‚ â€¢ LRU Cache     â”‚  â”‚ â€¢ Identification â”‚                â”‚
â”‚  â”‚ â€¢ Persistence   â”‚  â”‚ â€¢ Retrieval      â”‚                â”‚
â”‚  â”‚ â€¢ Providers     â”‚  â”‚ â€¢ Processing     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚           â”‚                    â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         TaskManager                   â”‚                â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚
â”‚  â”‚ â€¢ Background Summarization            â”‚                â”‚
â”‚  â”‚ â€¢ Ghost Task Detection                â”‚                â”‚
â”‚  â”‚ â€¢ Lifecycle Management                â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Background Tasks

| Task | Purpose | Default Interval |
|------|---------|-----------------|
| **Memory Summarization** | Clusters and consolidates related older memories | 2 hours |
| **Error Logging** | Reports error counters for monitoring | 30 minutes |
| **Date Updates** | Maintains current temporal context | 1 hour |

## ğŸ›ï¸ Configuration

All settings are configurable via Open WebUI valves:

### Embedding Settings
- **Provider Type**: `local` or `openai_compatible`
- **Model Name**: Choose your embedding model
- **API Configuration**: URL and API key for remote providers

### LLM Settings
- **Provider**: Ollama or OpenAI-compatible APIs
- **Model Selection**: Configure analysis and summarization models
- **Endpoints**: Custom API URLs

### Memory Management
- **Confidence Threshold**: Minimum confidence for memory extraction (default: 0.7)
- **Similarity Threshold**: Vector similarity cutoff for retrieval (default: 0.6)
- **Max Related Memories**: Number of memories to inject per prompt (default: 5)
- **Task Intervals**: Customize background processing schedules

## ğŸ“¦ Installation

1. Download `adaptive_memory_v4.0.py`
2. Navigate to Open WebUI â†’ Functions
3. Upload the plugin file
4. Configure valves according to your setup
5. Enable the function for desired models

## ğŸ”§ Requirements

**Core Dependencies** (included with Open WebUI):
- `numpy`, `aiohttp`, `pydantic`

**Optional Dependencies**:
- `sentence-transformers` - For local embedding models (falls back to API provider if not installed)
- `prometheus-client` - For metrics instrumentation (gracefully disabled if not available)

## ğŸ’¡ How It Works

1. **Extraction**: User messages are analyzed by an LLM to identify memorable information
2. **Filtering**: Multi-layered pipeline focuses on user-specific facts, not general knowledge
3. **Storage**: Memories are categorized, tagged, and stored with vector embeddings
4. **Retrieval**: Semantic search finds relevant memories for each conversation
5. **Injection**: Top-N memories are added to the system prompt for context
6. **Maintenance**: Background tasks consolidate and optimize memory over time

## ğŸ› ï¸ Recent Improvements (v4.0.1)

âœ… **Fixed**: Lock management now uses regular dict instead of WeakValueDictionary to prevent premature garbage collection  
âœ… **Enhanced**: Explicit lock cleanup prevents unbounded memory growth  
âœ… **Improved**: Background task scavenger eliminates ghost tasks  
âœ… **Added**: Comprehensive task lifecycle management

## ğŸ¤ Contributing

This is a fork of the original OpenWebUI Adaptive Memory plugin, evolved with enterprise-grade features and architectural improvements. Contributions, issues, and feature requests are welcome!

## ğŸ“„ License

Follow the original Open WebUI licensing terms.

---

**Made with â¤ï¸ for the Open WebUI community**
